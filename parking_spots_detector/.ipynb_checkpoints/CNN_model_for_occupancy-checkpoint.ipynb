{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import os\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Test and Train Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381 164\n"
     ]
    }
   ],
   "source": [
    "files_train = 0\n",
    "files_validation = 0\n",
    "\n",
    "cwd = os.getcwd()\n",
    "folder = 'train_data/train'\n",
    "for sub_folder in os.listdir(folder):\n",
    "    path, dirs, files = next(os.walk(os.path.join(folder,sub_folder)))\n",
    "    files_train += len(files)\n",
    "\n",
    "\n",
    "folder = 'train_data/test'\n",
    "for sub_folder in os.listdir(folder):\n",
    "    path, dirs, files = next(os.walk(os.path.join(folder,sub_folder)))\n",
    "    files_validation += len(files)\n",
    "\n",
    "print(files_train,files_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Set key parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 48, 48\n",
    "train_data_dir = \"train_data/train\"\n",
    "validation_data_dir = \"train_data/test\"\n",
    "nb_train_samples = files_train\n",
    "nb_validation_samples = files_validation\n",
    "batch_size = 32\n",
    "epochs = 15\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build model on top of a trained VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 79s 1us/step\n"
     ]
    }
   ],
   "source": [
    "model = applications.VGG16(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "# Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\n",
    "for layer in model.layers[:10]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "# x = Dense(512, activation=\"relu\")(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "# x = Dense(256, activation=\"relu\")(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "predictions = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model\n",
    "model_final = Model(input = model.input, output = predictions)\n",
    "\n",
    "# compile the model\n",
    "model_final.compile(loss = \"categorical_crossentropy\", \n",
    "                    optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), \n",
    "                    metrics=[\"accuracy\"]) # See learning rate is very low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 381 images belonging to 2 classes.\n",
      "Found 164 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Initiate the train and test generators with data Augumentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "horizontal_flip = True,\n",
    "fill_mode = \"nearest\",\n",
    "zoom_range = 0.1,\n",
    "width_shift_range = 0.1,\n",
    "height_shift_range=0.1,\n",
    "rotation_range=5)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "horizontal_flip = True,\n",
    "fill_mode = \"nearest\",\n",
    "zoom_range = 0.1,\n",
    "width_shift_range = 0.1,\n",
    "height_shift_range=0.1,\n",
    "rotation_range=5)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "train_data_dir,\n",
    "target_size = (img_height, img_width),\n",
    "batch_size = batch_size,\n",
    "class_mode = \"categorical\")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "validation_data_dir,\n",
    "target_size = (img_height, img_width),\n",
    "class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model according to the conditions\n",
    "checkpoint = ModelCheckpoint(\"car1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  if __name__ == '__main__':\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=15, validation_data=<keras.pre..., callbacks=[<keras.ca..., steps_per_epoch=11, validation_steps=164)`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      " 6/11 [===============>..............] - ETA: 16s - loss: 0.7555 - accuracy: 0.3958"
     ]
    }
   ],
   "source": [
    "### Start training!\n",
    "\n",
    "history_object = model_final.fit_generator(\n",
    "train_generator,\n",
    "samples_per_epoch = nb_train_samples,\n",
    "epochs = epochs,\n",
    "validation_data = validation_generator,\n",
    "nb_val_samples = nb_validation_samples,\n",
    "callbacks = [checkpoint, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(history_object.history.keys())\n",
    "plt.plot(history_object.history['acc'])\n",
    "plt.plot(history_object.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
